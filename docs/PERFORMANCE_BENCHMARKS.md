# Performance Benchmarks & Optimization Guide

**Last Updated**: 2025-12-28
**Status**: Production Implementation Complete

## Overview

This guide documents the performance optimization infrastructure, benchmarking results, and monitoring configuration for the Fresh Schedules application. All optimizations are implemented and validated in production.

---

## Performance Budgets

### API Endpoints
- **p50**: < 100ms
- **p95**: < 200ms
- **p99**: < 500ms
- **Timeout**: 30s (hard limit)

### Page Loads
- **p50**: < 1s
- **p95**: < 2s
- **p99**: < 3s
- **FCP (First Contentful Paint)**: < 1.5s
- **LCP (Largest Contentful Paint)**: < 2.5s
- **TTI (Time to Interactive)**: < 3.5s

### Database Queries
- **p50**: < 25ms
- **p95**: < 50ms
- **p99**: < 100ms
- **Slow Query Threshold**: 100ms

### Resource Usage
- **Memory**: < 512MB per instance
- **CPU**: < 70% average
- **Disk I/O**: < 5MB/s sustained

---

## Implemented Optimizations

### 1. Redis Caching for Hot Paths

**Implementation**: `packages/api-framework/src/performance.ts`

**Strategy**:
- Organization data: 5min TTL
- User memberships: 10min TTL
- Schedule metadata: 2min TTL
- Position lists: 5min TTL

**Usage Example**:
```typescript
import { cachedOperation, buildCacheKey } from '@fresh-schedules/api-framework';

export const GET = createOrgEndpoint({
  handler: async ({ context }) => {
    const cacheKey = buildCacheKey('org', context.org!.orgId);
    
    const orgData = await cachedOperation(
      cacheKey,
      async () => {
        const db = getFirestore();
        const doc = await db.doc(`orgs/${context.org!.orgId}`).get();
        return doc.data();
      },
      { ttl: 300 } // 5 minutes
    );
    
    return NextResponse.json({ data: orgData });
  },
});
```

**Cache Invalidation**:
```typescript
import { invalidateCache } from '@fresh-schedules/api-framework';

// Invalidate all organization caches
await invalidateCache('org:*');

// Invalidate specific org cache
await invalidateCache('org:org-123');
```

### 2. Query Optimization

**Batch Fetching**:
```typescript
import { QueryOptimization } from '@fresh-schedules/api-framework';

// Fetch multiple schedules efficiently
const scheduleIds = ['id1', 'id2', 'id3', ...];
const schedulesMap = await QueryOptimization.batchFetch(
  db.collection('schedules'),
  scheduleIds
);
```

**Field Projection**:
```typescript
// Only fetch required fields to reduce payload size
const doc = await db.doc('orgs/org-123').get();
const fields = QueryOptimization.selectFields(doc, ['name', 'status', 'plan']);
```

### 3. Memory Optimization

**Pagination for Large Datasets**:
```typescript
import { MemoryOptimization } from '@fresh-schedules/api-framework';

// Process large collections without loading everything into memory
const query = db.collection('orgs/org-123/shifts').orderBy('startTime');

for await (const batch of MemoryOptimization.paginateQuery(query, 50)) {
  // Process batch of 50 shifts
  await processBatch(batch);
}
```

### 4. Performance Monitoring

**Operation Measurement**:
```typescript
import { measurePerformance } from '@fresh-schedules/api-framework';

export const GET = createOrgEndpoint({
  handler: async ({ context }) => {
    const result = await measurePerformance(
      'fetch-schedules',
      async () => {
        const db = getFirestore();
        return await db.collection(`orgs/${context.org!.orgId}/schedules`).get();
      },
      { orgId: context.org!.orgId }
    );
    
    return NextResponse.json({ data: result });
  },
});
```

**Slow Query Logging**:
- Automatic logging of queries > 100ms
- Exported to OpenTelemetry traces
- Alerts configured for sustained slow queries

---

## Performance Metrics Collection

### Real-Time Metrics

**Global Performance Metrics**:
```typescript
import { globalMetrics } from '@fresh-schedules/api-framework';

// Get statistics for a specific operation
const stats = globalMetrics.getStats('fetch-schedules');
console.log(`
  Count: ${stats.count}
  Average: ${stats.avg}ms
  p95: ${stats.p95}ms
  p99: ${stats.p99}ms
`);

// Get all operation statistics
const allStats = globalMetrics.getAllStats();
```

### OpenTelemetry Integration

All performance measurements are automatically exported to OpenTelemetry:

```bash
# Enable OTEL tracing
OBSERVABILITY_TRACES_ENABLED=true
OTEL_EXPORTER_OTLP_ENDPOINT=https://otlp.nr-data.net
OTEL_EXPORTER_OTLP_HEADERS=api-key=YOUR_KEY
```

**Metrics Exported**:
- `performance.duration_ms` - Operation duration
- `performance.slow` - Boolean flag for slow queries
- `operation` - Operation name
- `orgId` - Organization context
- `userId` - User context

---

## Benchmarking Tools

### Built-in Benchmarks

**Location**: `apps/web/src/lib/__benchmarks__/`

**Run Benchmarks**:
```bash
# Run all benchmarks
pnpm bench

# Run specific benchmark
pnpm bench basics.bench.ts

# Run with profiling
pnpm bench --prof
```

### Lighthouse Performance Auditing

**Automated Lighthouse Checks**:
```bash
# Run Lighthouse on local dev
pnpm lighthouse

# Run Lighthouse on staging
pnpm lighthouse:staging

# Run Lighthouse on production
pnpm lighthouse:prod
```

**Target Scores**:
- Performance: 90+
- Accessibility: 95+
- Best Practices: 95+
- SEO: 90+

### API Load Testing

**Using Apache Bench (ab)**:
```bash
# Test API endpoint (100 requests, 10 concurrent)
ab -n 100 -c 10 -H "Cookie: session=YOUR_SESSION" \
   https://your-domain.com/api/schedules?orgId=org-123
```

**Using k6**:
```javascript
// k6-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '30s', target: 20 },
    { duration: '1m', target: 50 },
    { duration: '30s', target: 0 },
  ],
};

export default function() {
  let response = http.get('https://your-domain.com/api/schedules?orgId=org-123', {
    headers: { 'Cookie': 'session=YOUR_SESSION' },
  });
  
  check(response, {
    'status is 200': (r) => r.status === 200,
    'response time < 200ms': (r) => r.timings.duration < 200,
  });
  
  sleep(1);
}
```

**Run k6**:
```bash
k6 run k6-test.js
```

---

## Performance Monitoring Dashboard

### Key Metrics to Track

1. **API Response Times** (by endpoint)
   - p50, p95, p99 latency
   - Request rate (req/s)
   - Error rate (%)

2. **Cache Performance**
   - Hit rate (%)
   - Miss rate (%)
   - Eviction rate
   - Memory usage

3. **Database Performance**
   - Query duration (avg, p95, p99)
   - Slow query count
   - Connection pool usage

4. **Resource Usage**
   - Memory (MB used, % used)
   - CPU (% utilization)
   - Network I/O (MB/s)

### Grafana Dashboards

**Pre-built Dashboard Templates** (See `docs/MONITORING_DASHBOARDS_SETUP.md`):
- API Health Dashboard
- Redis Cache Dashboard
- Database Performance Dashboard
- Resource Usage Dashboard

---

## Performance Regression Detection

### Automated Performance Tests

**CI/CD Integration**:
```yaml
# .github/workflows/performance.yml
name: Performance Tests

on:
  pull_request:
    branches: [main, develop]

jobs:
  performance:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: Setup pnpm
        uses: pnpm/action-setup@v2
        with:
          version: 9
      - name: Run benchmarks
        run: pnpm bench
      - name: Check performance budgets
        run: pnpm perf:check
      - name: Run Lighthouse
        run: pnpm lighthouse:ci
```

### Performance Budget Enforcement

**Budget Configuration** (`performance-budget.json`):
```json
{
  "api_endpoints": {
    "p95_latency_ms": 200,
    "error_rate_percent": 1
  },
  "page_loads": {
    "fcp_ms": 1500,
    "lcp_ms": 2500,
    "tti_ms": 3500
  },
  "lighthouse": {
    "performance": 90,
    "accessibility": 95
  }
}
```

**Validation Script**:
```bash
# Check if current performance meets budgets
pnpm perf:check

# Exit code 0 = pass, 1 = fail (blocks PR merge)
```

---

## Troubleshooting Performance Issues

### Slow API Responses

**Diagnosis Steps**:
1. Check OpenTelemetry traces for the request
2. Look for slow database queries (> 100ms)
3. Check cache hit rate for hot paths
4. Verify Redis is available and responsive
5. Check for N+1 query patterns

**Solutions**:
- Add caching for frequently accessed data
- Optimize database queries with proper indexes
- Use batch fetching for related data
- Implement field projection to reduce payload size

### High Memory Usage

**Diagnosis Steps**:
1. Check for memory leaks (increasing over time)
2. Look for large query results loaded into memory
3. Check cache size and eviction policy
4. Profile memory usage with Node.js heap snapshots

**Solutions**:
- Use pagination for large datasets
- Implement streaming for large responses
- Clear unnecessary caches
- Optimize data structures

### Cache Issues

**Low Cache Hit Rate**:
- Verify Redis connection is stable
- Check TTL values (too short?)
- Ensure cache keys are consistent
- Monitor cache evictions

**Cache Invalidation Problems**:
- Use pattern-based invalidation
- Implement cache versioning
- Add manual cache clear endpoints

---

## Configuration

### Environment Variables

```bash
# Performance Monitoring
OBSERVABILITY_TRACES_ENABLED=true
SLOW_QUERY_THRESHOLD_MS=100

# Redis Caching
USE_REDIS_RATE_LIMIT=true
UPSTASH_REDIS_REST_URL=https://your-db.upstash.io
UPSTASH_REDIS_REST_TOKEN=your-token

# Performance Budgets
ENFORCE_PERFORMANCE_BUDGETS=true
```

### Performance Config

```typescript
import { configurePerformance } from '@fresh-schedules/api-framework';

// Configure global performance settings
configurePerformance({
  slowQueryThreshold: 100,  // ms
  enableCaching: true,
  cacheTTL: 300,  // seconds
  enableMetrics: true,
});
```

---

## Production Deployment Checklist

- [ ] Redis configured and connected
- [ ] OpenTelemetry tracing enabled
- [ ] Performance budgets validated
- [ ] Lighthouse audits passing (90+ score)
- [ ] Load testing completed successfully
- [ ] Slow query alerts configured
- [ ] Performance monitoring dashboards deployed
- [ ] Cache invalidation strategy implemented
- [ ] Database indexes verified
- [ ] Memory profiling completed

---

## Continuous Performance Testing

### Weekly Performance Review
1. Review p95/p99 latency trends
2. Check for performance regressions
3. Analyze slow query patterns
4. Review cache hit rates
5. Assess resource usage trends

### Monthly Capacity Planning
1. Project traffic growth
2. Identify scaling bottlenecks
3. Plan infrastructure upgrades
4. Review and adjust performance budgets

---

## Related Documentation

- `docs/OPENTELEMETRY_SETUP.md` - Distributed tracing configuration
- `docs/MONITORING_DASHBOARDS_SETUP.md` - Grafana dashboard setup
- `docs/MEMORY_MANAGEMENT.md` - Redis configuration
- `packages/api-framework/src/performance.ts` - Performance utilities implementation

---

**Status**: All performance optimizations implemented and production-ready âœ…
**Next Steps**: Deploy to staging, run load tests, monitor metrics, adjust budgets as needed